{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "3c1031e",
        "execution_millis": 696,
        "execution_start": 1606834122810,
        "cell_id": "00000-9b307470-b924-4650-9dee-5cc83ac832ed",
        "deepnote_cell_type": "code"
      },
      "source": "import praw\nimport csv\nimport nltk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Intializing reddit client",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00001-ed309007-7019-44b2-ada4-1020760f6764",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "c60c389a",
        "execution_millis": 0,
        "execution_start": 1606834123530,
        "cell_id": "00002-e70a2606-715d-43ad-a1fe-6b548831b313",
        "deepnote_cell_type": "code"
      },
      "source": "reddit = praw.Reddit(client_id = 'nz04TlX3jb7wHw', client_secret = 'nXjxefn8FSkCH04dxihWFlFdOcTFrA',\n                     username = 'Trapnova',password = 'ayush@flash121',\n                     user_agent = 'prawTutorial')",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "7d621e95",
        "execution_millis": 0,
        "execution_start": 1606834123531,
        "cell_id": "00003-41d7ccdc-e761-4145-a513-a34032d9239f",
        "deepnote_cell_type": "code"
      },
      "source": "subreddit = reddit.subreddit('AskReddit')\nhot_python = subreddit.top(limit = 90)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "66ca55c2",
        "execution_millis": 0,
        "execution_start": 1606834123532,
        "cell_id": "00004-775aaaea-2e94-4b71-9432-ad3933495e33",
        "deepnote_cell_type": "code"
      },
      "source": "title = []\nquestion = []\nscore = []\ndate = []\nnum_comments = []\nscore_ratio = []\ncount = 0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Function for Implementing Unix to year",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00005-2ec315f7-9aea-425b-9fc3-efbf74747bee",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "c311bf4d",
        "execution_millis": 1,
        "execution_start": 1606834123533,
        "cell_id": "00006-3e27ab34-398f-43fe-bda5-02b30a5d3bcb",
        "deepnote_cell_type": "code"
      },
      "source": "def unix_year(time):\n  month = ((time/86400)//365)\n  year = 1970 + int(month)\n  return year",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Extracting information from reddit and storing it into respective List ",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00007-36c933c3-656b-474c-b4fb-25bab75891bf",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "3201f2d5",
        "execution_millis": 1299,
        "execution_start": 1606834123578,
        "cell_id": "00008-719861c8-b789-4572-8e4a-de16c95a6839",
        "deepnote_cell_type": "code"
      },
      "source": "for submission in hot_python:\n    \n    if not submission.stickied:\n        \n        question.append(submission.title)\n        title.append(submission.title.split())\n        score.append(submission.score)\n        time = submission.created\n        date.append(unix_year(time))\n        num_comments.append(submission.num_comments)\n        score_ratio.append(submission.upvote_ratio)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Importing and implememnting stop words from nltk corpus on title list",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00009-e4e6b19b-7121-410a-bc3b-2dfdb5c2c74f",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "execution_millis": 36,
        "output_cleared": false,
        "source_hash": "a26e6313",
        "execution_start": 1606834124881,
        "cell_id": "00010-a630beca-3d97-45c2-a102-ab391b35cd92",
        "deepnote_cell_type": "code"
      },
      "source": "\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nstop_words = set(stopwords.words(\"english\"))\n",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "971341e7",
        "execution_millis": 2,
        "execution_start": 1606834124921,
        "cell_id": "00011-e7b092c8-b156-4f1a-9071-4e6c410e7514",
        "deepnote_cell_type": "code"
      },
      "source": "title1 = [[]]*len(title)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "f486b76d",
        "execution_millis": 1,
        "execution_start": 1606834124927,
        "cell_id": "00012-5a88fd4b-1d43-48fc-91dc-66c25e55dec7",
        "deepnote_cell_type": "code"
      },
      "source": "import string",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "f522866b",
        "execution_millis": 2,
        "execution_start": 1606834124931,
        "cell_id": "00013-533b879c-4b1a-4c29-b354-5dd19abf4bf8",
        "deepnote_cell_type": "code"
      },
      "source": "punctuation = '!#$%&\\\"()*+,-./:;<=>?@[\\\\]^_`{|}~'",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "e6c04caa",
        "execution_millis": 0,
        "execution_start": 1606834124977,
        "cell_id": "00014-a622fe6c-3364-4345-bb77-148b8838137d",
        "deepnote_cell_type": "code"
      },
      "source": "for i in range(len(title)):\n    x = []\n    for j in range(len(title[i])):\n        if title[i][j] in stop_words:\n            pass\n        else:\n            x.append(title[i][j].translate(str.maketrans(\"\",\"\",punctuation)))\n    title1[i] = x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Lemmatizing the words",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00015-20fa635a-3763-42ef-b5ad-ef277afacd17",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "f2dcaee9",
        "execution_millis": 1443,
        "execution_start": 1606834124978,
        "cell_id": "00016-2b3d3e42-cc59-413d-8dc4-0ea09856cb90",
        "deepnote_cell_type": "code"
      },
      "source": "nltk.download('wordnet')\nfrom nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\n\n\n\nfor i in range(len(title1)):\n    for j in range(len(title1[i])):\n        title1[i][j] = title1[i][j].replace(\",\",\"\")\n        title1[i][j] = wordnet_lemmatizer.lemmatize(title1[i][j],pos = 'v')\n\n",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "dc910d78",
        "execution_millis": 1,
        "is_code_hidden": true,
        "execution_start": 1606834126426,
        "cell_id": "00017-9ea5436c-98c8-4df3-8f4e-3427d19bc17e",
        "deepnote_cell_type": "code"
      },
      "source": "# Initial Version\n# Until here the code is in preferred format where the title 1 and title 1 stores the individual \n# words in a sentence in the same list but after here we're storing each word as a key whereas we \n# want to store each Question/sentence as a key and each word as different value. But here we're\n# going to store all the words that belong to one question as a single list. SO if there are 10000 questions\n# there will be  a column called words which will have 10000 items and each item will be a list containing the\n# words in the question seperated by comma\n\n# --------------------------------------------------------------\n# words = {}\n#--------------------------------------------------------------\n\n# for i in range(len(title1)):\n#     for j in range(len(title1[i])):\n#         curr_word = title1[i][j]\n#         # print(words.keys())\n#         if curr_word in words.keys():\n#             words[curr_word][4] += 1\n#             words[curr_word][0] = words[curr_word][0]+score[i]\n#             words[curr_word][1] = words[curr_word][1]+date[i]\n#             words[curr_word][2] = words[curr_word][2]+num_comments[i]\n#             words[curr_word][3] = words[curr_word][3]+score_ratio[i]\n#         else:\n#             words[curr_word] = [score[i],date[i],num_comments[i],score_ratio[i],1]\n\n#--------------------------------------------------------\n\n# Averaging each value in the dictionary based on the number of times it appears\n# Divide each value by it's count also check first if the 4 index of the dictionary has > 1 value.\n\n#--------------------------------------------------------\n\n# for i in words.keys():\n#     if words[i][4]>1:\n#         words[i][0] = words[i][0]/words[i][4]\n#         words[i][1] = words[i][1]/words[i][4]\n#         words[i][2] = words[i][2]/words[i][4]\n#         words[i][3] = words[i][3]/words[i][4]\n\n#--------------------------------------------------------\n\n# Writing list into csv file.\n\n#--------------------------------------------------------\n\n# with open(\"data.csv\",\"w\",newline = \"\") as file:\n\n#     writer = csv.writer(file)\n#     writer.writerow([\"Title\",\"Score\",\"Date\",\"Num_comments\",\"Score_ratio\",\"Count\"])\n    \n#     for i in words.keys():\n#             writer.writerow([i,words[i][0],words[i][1],words[i][2],words[i][3],words[i][4]])",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# DICTIONARY",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00018-dd2b7d67-0386-467b-9c82-a9f375b32a77",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "394db5fe",
        "execution_millis": 2,
        "execution_start": 1606834126430,
        "cell_id": "00019-2ad2f3aa-2aad-4a6c-bdee-5b1652208db3",
        "deepnote_cell_type": "code"
      },
      "source": "words1 = {}",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "66305263",
        "execution_millis": 2,
        "execution_start": 1606834126435,
        "cell_id": "00020-5d38e03c-7949-4954-a6b1-4d0c4529aef0",
        "deepnote_cell_type": "code"
      },
      "source": "for i in range(len(title)):\n    words1[question[i]] = [title1[i],score[i],date[i],num_comments[i],score_ratio[i]]",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "1278 words in title",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00021-a8efec2e-fdec-46b6-828a-46904625c5b6",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "18d6f3af",
        "execution_millis": 3,
        "execution_start": 1606834126441,
        "cell_id": "00022-8cc2ae22-3dc5-42ec-ace1-68754815ec0a",
        "deepnote_cell_type": "code"
      },
      "source": "countx = 0\nfor i in range(len(title1)):\n    countx += len(title1[i])\n\nprint(countx)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1175\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "d46426c9",
        "execution_millis": 2,
        "is_code_hidden": false,
        "execution_start": 1606834126446,
        "cell_id": "00023-216a77a1-e210-4916-887b-10834d6738d3",
        "deepnote_cell_type": "code"
      },
      "source": "# Writing to CSV FIle\n# Tis IS REDUNDANT\n\n\n# with open(\"data.csv\",\"w\",newline = \"\") as file:\n\n#     writer = csv.writer(file)\n#     writer.writerow([\"Question\",\"Title\",\"Score\",\"Date\",\"Num_comments\",\"Score_ratio\",\"Count\"])\n    \n#     for i in words1.keys():\n#             writer.writerow([i,words1[i][0],words1[i][1],words1[i][2],words1[i][3],words1[i][4]])\n\n\n# The below line is for using Dictionary to Csv file and then using it in Fit_transform\n# values = [[i] for i in reddit_data[\"Title\"]]\n# [['People'], ['pooped'], ['pooped']]",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Pandas",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00024-00b1b4e7-1284-4c5a-a39b-dcc6a999894a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "cb1d94a2",
        "execution_millis": 5,
        "execution_start": 1606834126454,
        "cell_id": "00025-479eb7a4-276b-4c33-b99e-e936d12eb7f0",
        "deepnote_cell_type": "code"
      },
      "source": "import pandas as pd\n\nreddit_data = pd.read_csv('/home/jovyan/work/data.csv')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Storing classes for MLB",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00026-a1637ee6-6a6c-47e1-9209-1afa94015f21",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "414a441a",
        "execution_millis": 0,
        "execution_start": 1606834126483,
        "cell_id": "00027-3072d776-5411-43bb-8a8a-1fe2f4e8c935",
        "deepnote_cell_type": "code"
      },
      "source": "# Below Line is used using Pandas to Dictionary:\n# So Words is converted to pandas dataframe and then fit_transform is applied.",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "b1fe79bf",
        "execution_millis": 0,
        "execution_start": 1606834126484,
        "cell_id": "00028-f7196471-51b9-4759-b7a3-da7efa7bc80e",
        "deepnote_cell_type": "code"
      },
      "source": "labels = []\nfor i in title1:\n    for j in i:\n        if j in labels:\n            pass\n        else:\n            labels.append(j)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Storing Dictionary as Dataframe",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00029-8cbfbb6b-7367-497c-a8af-10028fc9cb04",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "4f11b1a1",
        "execution_millis": 0,
        "execution_start": 1606834126485,
        "cell_id": "00030-9a837f8f-3288-46cb-b1a7-eb0ffb8a293b",
        "deepnote_cell_type": "code"
      },
      "source": "xyz = pd.DataFrame.from_dict(words1,orient=\"index\",columns=[\"Title\",\"Score\",\"Date\",\"Num_comments\",\"Score_ratio\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "ed3d5b94",
        "execution_millis": 2,
        "execution_start": 1606834126486,
        "cell_id": "00031-58c3fe19-753d-4d6b-9136-0edc7620ded8",
        "deepnote_cell_type": "code"
      },
      "source": "# MultiLabelBinarizer\n# txt = [['book', 'read'],['cup', 'drink']]\n# mlb = MultiLabelBinarizer(classes=(\"drink\",\"cup\",\"book\", \"read\"))\n# mlb.fit_transform(txt)\n# array([[0, 0, 1, 1],\n#        [1, 1, 0, 0]])",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Multi-Label Binarizer",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00032-03b6372d-454a-4659-b911-0f7a45633b56",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "c1bb7d64",
        "execution_millis": 1,
        "execution_start": 1606834126489,
        "cell_id": "00033-697eba7f-95fd-4eb9-a6b8-27b36e3e403b",
        "deepnote_cell_type": "code"
      },
      "source": "from sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer(classes = labels)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "70b56ded",
        "execution_millis": 1,
        "execution_start": 1606834126499,
        "cell_id": "00034-821f3d35-f641-45a8-8ab4-8278eb4dfcd9",
        "deepnote_cell_type": "code"
      },
      "source": "ft = mlb.fit_transform(xyz[\"Title\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "source_hash": "a8e2259c",
        "execution_millis": 11,
        "execution_start": 1606834126500,
        "cell_id": "00035-5965792a-7c59-41c4-a09b-40dd007e9ed6",
        "deepnote_cell_type": "code"
      },
      "source": "column = pd.DataFrame(ft,columns=labels)\ncolumn.index = xyz.index\nxyz = pd.concat([xyz,column],axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Increase the column size",
      "metadata": {
        "tags": [],
        "output_cleared": false,
        "cell_id": "00036-eec710c2-4682-4f43-a8f1-fb7d427a1c0c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=616e01bf-c35a-44d0-aacb-9c74ce127fb6' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "70eb471d-588f-4d0c-b917-a781d3ba084b",
    "deepnote_execution_queue": [],
    "deepnote": {}
  }
}